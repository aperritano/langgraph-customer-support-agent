{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Quick Start: Customer Support Bot\n",
    "\n",
    "A **5-minute** introduction to building a customer support agent with LangGraph and Ollama.\n",
    "\n",
    "## Prerequisites\n",
    "```bash\n",
    "# 1. Install Ollama: https://ollama.ai\n",
    "ollama pull llama3.1:latest  # or use any model you have available\n",
    "\n",
    "# 2. Install packages\n",
    "%pip install langgraph langchain-ollama langchain-core\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-ollama in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-core in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph) (3.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph) (1.0.1)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph) (0.2.9)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph) (2.12.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.11.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langchain-ollama) (0.6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langchain-core) (0.4.38)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langgraph langchain-ollama langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a Simple Tool\n",
    "\n",
    "Tools let the bot take actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tools created\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_return_policy() -> str:\n",
    "    \"\"\"Get the store's return policy.\"\"\"\n",
    "    return \"Returns accepted within 30 days. Items must be unused in original packaging.\"\n",
    "\n",
    "@tool\n",
    "def track_order(order_id: str) -> str:\n",
    "    \"\"\"Track an order by ID.\"\"\"\n",
    "    return f\"Order #{order_id} is in transit. Expected delivery: Nov 1, 2025.\"\n",
    "\n",
    "tools = [get_return_policy, track_order]\n",
    "print(\"‚úÖ Tools created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Connect to Ollama\n",
    "\n",
    "Use a local LLM - no API keys needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ollama connected with llama3.1:latest\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Using llama3.1:latest (available on your system)\n",
    "llm = ChatOllama(model=\"llama3.1:latest\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"‚úÖ Ollama connected with llama3.1:latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build the Graph\n",
    "\n",
    "This creates the agent workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Graph built\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, END, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Ensure llm_with_tools is available (redefine if needed)\n",
    "if 'llm_with_tools' not in globals():\n",
    "    from langchain_ollama import ChatOllama\n",
    "    llm = ChatOllama(model=\"llama3.1:latest\", temperature=0)\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Agent node: decides what to do\n",
    "def agent(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Router: decides if we need tools\n",
    "def should_continue(state: MessagesState):\n",
    "    last = state[\"messages\"][-1]\n",
    "    return \"tools\" if last.tool_calls else END\n",
    "\n",
    "# Build graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"agent\", agent)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", END: END})\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "graph = workflow.compile()\n",
    "print(\"‚úÖ Graph built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Test It!\n",
    "\n",
    "Ask questions and watch it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Based on the output of the tool call, I can provide an answer to the user's question.\n",
      "\n",
      "The return policy allows for returns within 30 days, and items must be unused in their original packaging. This information should help the user understand what is required for a successful return.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Ensure graph is available\n",
    "if 'graph' not in globals():\n",
    "    print(\"‚ùå Graph not found. Please run the previous cells first.\")\n",
    "else:\n",
    "    # Test 1: Policy question\n",
    "    try:\n",
    "        result = graph.invoke({\"messages\": [HumanMessage(\"What's your return policy?\")]})\n",
    "        print(\"Bot:\", result[\"messages\"][-1].content)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        print(\"Make sure you've run all previous cells in order.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The tool call response indicates that the order is in transit and has an expected delivery date of November 1, 2025. I can now provide a formatted answer to your original question:\n",
      "\n",
      "\"Your order #12345 is currently in transit and is expected to be delivered on November 1, 2025.\"\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Order tracking\n",
    "if 'graph' in globals():\n",
    "    try:\n",
    "        result = graph.invoke({\"messages\": [HumanMessage(\"Track order #12345\")]})\n",
    "        print(\"Bot:\", result[\"messages\"][-1].content)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Graph not found. Please run the previous cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Chat Loop\n",
    "\n",
    "Have a conversation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: Hi, can you help me?\n",
      "Bot: You're welcome! I'd be happy to assist you further.\n",
      "\n",
      "What seems to be the issue or question you have?\n",
      "\n",
      "You: What's your return policy?\n",
      "Bot: Based on the output of the tool call, I can provide an answer to the user's question.\n",
      "\n",
      "The return policy allows for returns within 30 days, and items must be unused in their original packaging. This information should help the user understand what is required for a successful return.\n",
      "\n",
      "You: Can you track order #99999?\n",
      "Bot: The tool call response indicates that the order is in transit and has an expected delivery date of November 1, 2025.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def chat(message: str):\n",
    "    \"\"\"Simple chat function.\"\"\"\n",
    "    if 'graph' not in globals():\n",
    "        print(\"‚ùå Graph not found. Please run the previous cells first.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"You: {message}\")\n",
    "    try:\n",
    "        result = graph.invoke({\"messages\": [HumanMessage(message)]})\n",
    "        response = result[\"messages\"][-1].content\n",
    "        print(f\"Bot: {response}\\n\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Try it\n",
    "if 'graph' in globals():\n",
    "    chat(\"Hi, can you help me?\")\n",
    "    chat(\"What's your return policy?\")\n",
    "    chat(\"Can you track order #99999?\")\n",
    "else:\n",
    "    print(\"‚ùå Graph not found. Please run the previous cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ That's It!\n",
    "\n",
    "You've built a working customer support agent in 5 steps!\n",
    "\n",
    "### What Just Happened?\n",
    "1. **Tools** - You defined actions the bot can take\n",
    "2. **LLM** - Connected to local Ollama (free!)\n",
    "3. **Graph** - Created agent ‚Üí tools ‚Üí agent loop\n",
    "4. **Chat** - The bot decides which tools to use automatically\n",
    "\n",
    "### Next Steps\n",
    "- Add more tools for your use case\n",
    "- Try different Ollama models (`mistral:7b`, `qwen2.5:7b`)\n",
    "- Add conversation memory\n",
    "- Check out the full demo notebook: `customer_support_bot_demo.ipynb`\n",
    "\n",
    "### Try These Models\n",
    "```bash\n",
    "ollama pull mistral:7b      # Better reasoning\n",
    "ollama pull qwen2.5:7b      # Strong performance\n",
    "ollama pull llama3.1:8b     # Larger, more capable\n",
    "```\n",
    "\n",
    "### Resources\n",
    "- [LangGraph Docs](https://langchain-ai.github.io/langgraph/)\n",
    "- [Ollama Models](https://ollama.ai/library)\n",
    "- Full project: See `customer-support-bot.zip`\n",
    "\n",
    "**Happy coding! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
