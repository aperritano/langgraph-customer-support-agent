{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– Customer Support Bot - Interactive Demo\n",
    "\n",
    "This notebook demonstrates a complete customer support agent built with **LangGraph** and **Ollama**.\n",
    "\n",
    "## What You'll Learn\n",
    "- How to build a ReAct agent with LangGraph\n",
    "- Using local LLMs with Ollama\n",
    "- Creating and using tools\n",
    "- Managing conversation state\n",
    "\n",
    "## Prerequisites\n",
    "```bash\n",
    "# Install Ollama from https://ollama.ai\n",
    "ollama pull llama3.1:latest\n",
    "\n",
    "# Install dependencies\n",
    "pip install langgraph langchain-ollama langchain-core\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-ollama in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain-core in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph) (3.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph) (1.0.1)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph) (0.2.9)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph) (2.12.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.11.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langchain-ollama) (0.6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langchain-core) (0.4.38)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to install in notebook\n",
    "%pip install langgraph langchain-ollama langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Step 2: Define Support Tools\n",
    "\n",
    "These are the actions our bot can take to help customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tools defined:\n",
      "  - search_knowledge_base\n",
      "  - get_order_status\n",
      "  - initiate_return\n",
      "  - check_product_availability\n",
      "  - escalate_to_human\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Mock data\n",
    "MOCK_ORDERS = {\n",
    "    \"123456\": {\n",
    "        \"status\": \"in_transit\",\n",
    "        \"expected_delivery\": (datetime.now() + timedelta(days=2)).strftime(\"%b %d, %Y\"),\n",
    "        \"items\": [\"Wireless Headphones\", \"USB Cable\"],\n",
    "    },\n",
    "    \"789012\": {\n",
    "        \"status\": \"delivered\",\n",
    "        \"delivered_date\": (datetime.now() - timedelta(days=3)).strftime(\"%b %d, %Y\"),\n",
    "        \"items\": [\"Laptop Stand\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "@tool\n",
    "def search_knowledge_base(query: str, category: str = \"general\") -> str:\n",
    "    \"\"\"Search store knowledge base for policies and FAQ.\n",
    "    \n",
    "    Args:\n",
    "        query: Customer's question\n",
    "        category: Type (product, shipping, return, payment, general)\n",
    "    \"\"\"\n",
    "    kb = {\n",
    "        \"product\": \"All products come with 30-day warranty. Free shipping on orders over $50.\",\n",
    "        \"shipping\": \"Standard: 5-7 days (free over $50). Express: 2-3 days ($15). Overnight: next day ($25).\",\n",
    "        \"return\": \"Returns accepted within 30 days. Items must be unused in original packaging. Refund in 5-7 days.\",\n",
    "        \"payment\": \"We accept Visa, Mastercard, Amex, Discover, and PayPal. Secure processing via Stripe.\",\n",
    "        \"general\": \"Support hours: Mon-Fri 9AM-6PM EST. Email: support@store.com, Phone: 1-800-SUPPORT\",\n",
    "    }\n",
    "    return kb.get(category, kb[\"general\"])\n",
    "\n",
    "@tool\n",
    "def get_order_status(order_id: str) -> str:\n",
    "    \"\"\"Look up order status and tracking.\n",
    "    \n",
    "    Args:\n",
    "        order_id: Order number (6+ digits)\n",
    "    \"\"\"\n",
    "    order_id = order_id.replace(\"#\", \"\").strip()\n",
    "    order = MOCK_ORDERS.get(order_id)\n",
    "    \n",
    "    if not order:\n",
    "        return f\"Order #{order_id} not found. Please verify the order number.\"\n",
    "    \n",
    "    if order[\"status\"] == \"in_transit\":\n",
    "        return f\"Order #{order_id}: In transit. Expected delivery: {order['expected_delivery']}. Items: {', '.join(order['items'])}\"\n",
    "    elif order[\"status\"] == \"delivered\":\n",
    "        return f\"Order #{order_id}: Delivered on {order['delivered_date']}. Items: {', '.join(order['items'])}\"\n",
    "    \n",
    "    return f\"Order #{order_id} status: {order['status']}\"\n",
    "\n",
    "@tool\n",
    "def initiate_return(order_id: str, reason: str) -> str:\n",
    "    \"\"\"Start return process for an order.\n",
    "    \n",
    "    Args:\n",
    "        order_id: Order number to return\n",
    "        reason: Why (defective, wrong_item, changed_mind, etc.)\n",
    "    \"\"\"\n",
    "    order_id = order_id.replace(\"#\", \"\").strip()\n",
    "    return_id = f\"RMA-{order_id}-{abs(hash(reason)) % 1000:03d}\"\n",
    "    \n",
    "    return f\"\"\"Return authorized for order #{order_id}.\n",
    "Return ID: {return_id}\n",
    "Reason: {reason}\n",
    "Next steps: Return label will be emailed within 1 hour. Refund processed in 5-7 days after we receive item.\"\"\"\n",
    "\n",
    "@tool\n",
    "def check_product_availability(product_name: str) -> str:\n",
    "    \"\"\"Check if product is in stock.\n",
    "    \n",
    "    Args:\n",
    "        product_name: Name of the product\n",
    "    \"\"\"\n",
    "    inventory = {\n",
    "        \"laptop\": \"In stock - 15 units available\",\n",
    "        \"headphones\": \"Low stock - 3 units available\",\n",
    "        \"mouse\": \"Out of stock - Restock Nov 5, 2025\",\n",
    "    }\n",
    "    \n",
    "    for key, status in inventory.items():\n",
    "        if key in product_name.lower():\n",
    "            return f\"{product_name}: {status}\"\n",
    "    \n",
    "    return f\"Please provide more details about '{product_name}'\"\n",
    "\n",
    "@tool\n",
    "def escalate_to_human(reason: str, customer_message: str) -> str:\n",
    "    \"\"\"Escalate to human support agent.\n",
    "    \n",
    "    Args:\n",
    "        reason: Why escalation needed\n",
    "        customer_message: The triggering message\n",
    "    \"\"\"\n",
    "    ticket_id = f\"TICKET-{abs(hash(customer_message)) % 10000:04d}\"\n",
    "    return f\"\"\"Support ticket {ticket_id} created. A human agent will contact you within 15 minutes.\n",
    "Is there anything else I can help with while you wait?\"\"\"\n",
    "\n",
    "# Collect all tools\n",
    "tools = [\n",
    "    search_knowledge_base,\n",
    "    get_order_status,\n",
    "    initiate_return,\n",
    "    check_product_availability,\n",
    "    escalate_to_human,\n",
    "]\n",
    "\n",
    "print(\"âœ… Tools defined:\")\n",
    "for tool in tools:\n",
    "    print(f\"  - {tool.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Step 3: Set Up LLM with Ollama\n",
    "\n",
    "We'll use a local Ollama model for privacy and no API costs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ollama LLM initialized with tools\n",
      "Model: llama3.1:latest\n",
      "Tools available: 5\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Initialize Ollama\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:latest\",  # Fast and efficient model\n",
    "    temperature=0,  # Deterministic for customer support\n",
    ")\n",
    "\n",
    "# Bind tools to LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"âœ… Ollama LLM initialized with tools\")\n",
    "print(f\"Model: llama3.1:latest\")\n",
    "print(f\"Tools available: {len(tools)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ Step 4: Define State Schema\n",
    "\n",
    "State tracks the conversation as it flows through the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… State schema defined\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class SupportState(TypedDict):\n",
    "    \"\"\"State for customer support conversation.\"\"\"\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "print(\"âœ… State schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”„ Step 5: Build the LangGraph\n",
    "\n",
    "This creates the ReAct loop: Agent â†’ Tools â†’ Agent â†’ ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangGraph compiled successfully!\n",
      "\n",
      "Graph structure:\n",
      "  START â†’ agent â†’ [tools?] â†’ agent â†’ END\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import SystemMessage\n",
    "from typing import Literal\n",
    "\n",
    "# System prompt\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful customer support agent for an online store.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Use tools to help customers effectively\n",
    "2. Provide friendly, accurate, concise responses (2-3 sentences)\n",
    "3. Escalate to humans when needed (angry customers, complex issues)\n",
    "\n",
    "Available tools:\n",
    "- search_knowledge_base: Store policies and FAQ\n",
    "- get_order_status: Track orders\n",
    "- initiate_return: Process returns\n",
    "- check_product_availability: Check stock\n",
    "- escalate_to_human: Transfer to human agent\n",
    "\"\"\"\n",
    "\n",
    "def agent_node(state: SupportState) -> dict:\n",
    "    \"\"\"Agent decides which tools to call or provides answer.\"\"\"\n",
    "    messages = [SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: SupportState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"Route to tools or end.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "# Build graph\n",
    "workflow = StateGraph(SupportState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define flow\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"__end__\": END}\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "\n",
    "print(\"âœ… LangGraph compiled successfully!\")\n",
    "print(\"\\nGraph structure:\")\n",
    "print(\"  START â†’ agent â†’ [tools?] â†’ agent â†’ END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 6: Visualize the Graph (Optional)\n",
    "\n",
    "See the structure of your agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph nodes: ['__start__', 'agent', 'tools', '__end__']\n",
      "Graph edges: [Edge(source='__start__', target='agent', data=None, conditional=False), Edge(source='agent', target='__end__', data=None, conditional=True), Edge(source='agent', target='tools', data=None, conditional=True), Edge(source='tools', target='agent', data=None, conditional=False)]\n"
     ]
    }
   ],
   "source": [
    "# Uncomment if you have graphviz installed\n",
    "from IPython.display import Image, display\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    print(\"Install graphviz to see visualization: pip install pygraphviz\")\n",
    "\n",
    "print(\"Graph nodes:\", list(graph.get_graph().nodes.keys()))\n",
    "print(\"Graph edges:\", list(graph.get_graph().edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¬ Step 7: Test Single Message\n",
    "\n",
    "Let's ask about the return policy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ You: What's your return policy?\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: search_knowledge_base\n",
      "\n",
      "ðŸ¤– Bot: This response is based on the output of the `search_knowledge_base` tool, which provided information about our return policy. If you have any further questions or concerns, feel free to ask!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This response is based on the output of the `search_knowledge_base` tool, which provided information about our return policy. If you have any further questions or concerns, feel free to ask!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def chat(message: str, verbose: bool = True):\n",
    "    \"\"\"Send a message and get response.\"\"\"\n",
    "    if verbose:\n",
    "        print(f\"ðŸ’¬ You: {message}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # Track tool calls\n",
    "    tool_calls_made = []\n",
    "    \n",
    "    # Run the graph\n",
    "    for event in graph.stream(\n",
    "        {\"messages\": [HumanMessage(content=message)]},\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        last_msg = event[\"messages\"][-1]\n",
    "        \n",
    "        # Show tool calls\n",
    "        if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
    "            for tc in last_msg.tool_calls:\n",
    "                tool_name = tc[\"name\"]\n",
    "                if tool_name not in tool_calls_made and verbose:\n",
    "                    print(f\"ðŸ”§ Using tool: {tool_name}\")\n",
    "                    tool_calls_made.append(tool_name)\n",
    "        \n",
    "        # Show response\n",
    "        elif hasattr(last_msg, \"content\") and last_msg.content and last_msg.type == \"ai\":\n",
    "            if verbose:\n",
    "                print(f\"\\nðŸ¤– Bot: {last_msg.content}\\n\")\n",
    "            return last_msg.content\n",
    "\n",
    "# Test it!\n",
    "chat(\"What's your return policy?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 8: Test Order Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ You: Can you check the status of order #123456?\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: get_order_status\n",
      "\n",
      "ðŸ¤– Bot: Your order is currently in transit and is expected to be delivered on October 30, 2023. The items included are the Wireless Headphones and a USB Cable. If you have any other questions or concerns, feel free to ask!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your order is currently in transit and is expected to be delivered on October 30, 2023. The items included are the Wireless Headphones and a USB Cable. If you have any other questions or concerns, feel free to ask!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"Can you check the status of order #123456?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”„ Step 9: Test Return Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ You: I want to return order #789012 because it's defective\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: initiate_return\n",
      "\n",
      "ðŸ¤– Bot: Would you like to print the return shipping label or would you prefer us to email it to you?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Would you like to print the return shipping label or would you prefer us to email it to you?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"I want to return order #789012 because it's defective\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 10: Test Product Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ You: Do you have laptops in stock?\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: check_product_availability\n",
      "\n",
      "ðŸ¤– Bot: We currently have 15 laptops in stock. Would you like to place an order or check availability for a specific model?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'We currently have 15 laptops in stock. Would you like to place an order or check availability for a specific model?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"Do you have laptops in stock?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš¨ Step 11: Test Escalation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ You: This is ridiculous! I want to speak to a manager NOW!\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: escalate_to_human\n",
      "\n",
      "ðŸ¤– Bot: No, thank you. I'll just wait for the human to call me back.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"No, thank you. I'll just wait for the human to call me back.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"This is ridiculous! I want to speak to a manager NOW!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¬ Step 12: Multi-turn Conversation\n",
    "\n",
    "Let's have a back-and-forth conversation with memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Multi-turn Conversation with Memory\n",
      "============================================================\n",
      "\n",
      "ðŸ’¬ You: Hi, I need help with my order\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: search_knowledge_base\n",
      "\n",
      "ðŸ¤– Bot: I'd be happy to help you with your order! Can you please provide me with your order number so I can look into it further?\n",
      "\n",
      "ðŸ’¬ You: Order number is 123456\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: get_order_status\n",
      "\n",
      "ðŸ¤– Bot: Your order is currently in transit and expected to arrive on October 30th, 2025. You should receive your Wireless Headphones and USB Cable soon! Would you like me to check the tracking information for you?\n",
      "\n",
      "ðŸ’¬ You: When will it arrive?\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: search_knowledge_base\n",
      "\n",
      "ðŸ¤– Bot: Your order is expected to arrive within the standard timeframe of 5-7 business days, as it's a free shipping option. If you'd like to upgrade to express or overnight shipping for a faster delivery, please let me know!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Your order is expected to arrive within the standard timeframe of 5-7 business days, as it's a free shipping option. If you'd like to upgrade to express or overnight shipping for a faster delivery, please let me know!\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Rebuild graph with memory\n",
    "memory = MemorySaver()\n",
    "graph_with_memory = workflow.compile(checkpointer=memory)\n",
    "\n",
    "def chat_with_memory(message: str, thread_id: str = \"user-123\"):\n",
    "    \"\"\"Chat with conversation memory.\"\"\"\n",
    "    print(f\"ðŸ’¬ You: {message}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    for event in graph_with_memory.stream(\n",
    "        {\"messages\": [HumanMessage(content=message)]},\n",
    "        config=config,\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        last_msg = event[\"messages\"][-1]\n",
    "        \n",
    "        if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
    "            for tc in last_msg.tool_calls:\n",
    "                print(f\"ðŸ”§ Using tool: {tc['name']}\")\n",
    "        \n",
    "        elif hasattr(last_msg, \"content\") and last_msg.content and last_msg.type == \"ai\":\n",
    "            print(f\"\\nðŸ¤– Bot: {last_msg.content}\\n\")\n",
    "            return last_msg.content\n",
    "\n",
    "# Multi-turn conversation\n",
    "print(\"=\" * 60)\n",
    "print(\"Multi-turn Conversation with Memory\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "chat_with_memory(\"Hi, I need help with my order\")\n",
    "chat_with_memory(\"Order number is 123456\")\n",
    "chat_with_memory(\"When will it arrive?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ® Step 13: Interactive Chat Interface\n",
    "\n",
    "Chat with the bot interactively!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ¤– Customer Support Bot - Demo Mode\n",
      "============================================================\n",
      "Running demo conversation...\n",
      "\n",
      "ðŸ’¬ You: Hi, I need help with my order\n",
      "------------------------------------------------------------\n",
      "ðŸ’¬ You: Hi, I need help with my order\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: search_knowledge_base\n",
      "\n",
      "ðŸ¤– Bot: I'd be happy to help you with your order! Can you please provide me with your order number so I can look into it further?\n",
      "\n",
      "\n",
      "ðŸ’¬ You: My order number is 123456\n",
      "------------------------------------------------------------\n",
      "ðŸ’¬ You: My order number is 123456\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: get_order_status\n",
      "\n",
      "ðŸ¤– Bot: Your order is currently in transit and expected to arrive on October 30th, 2025. You should receive your Wireless Headphones and USB Cable soon! Is there anything else I can help you with?\n",
      "\n",
      "\n",
      "ðŸ’¬ You: When will it arrive?\n",
      "------------------------------------------------------------\n",
      "ðŸ’¬ You: When will it arrive?\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: search_knowledge_base\n",
      "\n",
      "ðŸ¤– Bot: Your order is expected to arrive within the standard timeframe of 5-7 business days, as it's a free shipping option. If you'd like to upgrade to express or overnight shipping for an additional fee, I can assist with that. Would you like me to look into upgrading your shipping?\n",
      "\n",
      "\n",
      "ðŸ’¬ You: What's your return policy?\n",
      "------------------------------------------------------------\n",
      "ðŸ’¬ You: What's your return policy?\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: search_knowledge_base\n",
      "\n",
      "ðŸ¤– Bot: You can return or exchange items within 30 days of delivery. Items must be in original condition with tags attached. Please initiate a return through our website for a prepaid return shipping label and instructions on how to proceed. Would you like me to guide you through the process?\n",
      "\n",
      "\n",
      "ðŸ’¬ You: I want to return order #789012 because it's defective\n",
      "------------------------------------------------------------\n",
      "ðŸ’¬ You: I want to return order #789012 because it's defective\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: initiate_return\n",
      "\n",
      "ðŸ¤– Bot: Your return has been initiated, and a prepaid return shipping label will be sent to you via email within the next hour. Please print out the label and attach it to your package when returning the defective item. Once we receive the item, your refund will be processed within 5-7 business days. If there's anything else I can assist with, feel free to ask!\n",
      "\n",
      "\n",
      "ðŸ’¬ You: Do you have laptops in stock?\n",
      "------------------------------------------------------------\n",
      "ðŸ’¬ You: Do you have laptops in stock?\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: check_product_availability\n",
      "\n",
      "ðŸ¤– Bot: We currently have 15 laptops in stock. Would you like to place an order or check the product details?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def interactive_chat():\n",
    "    \"\"\"Interactive chat loop.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ðŸ¤– Customer Support Bot - Interactive Mode\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Type 'quit' to exit\\n\")\n",
    "    \n",
    "    thread_id = \"interactive-session\"\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"ðŸ’¬ You: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "                print(\"\\nðŸ‘‹ Goodbye!\\n\")\n",
    "                break\n",
    "            \n",
    "            if not user_input:\n",
    "                continue\n",
    "            \n",
    "            print()\n",
    "            chat_with_memory(user_input, thread_id)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nðŸ‘‹ Goodbye!\\n\")\n",
    "            break\n",
    "\n",
    "def demo_chat():\n",
    "    \"\"\"Demo chat with predefined messages for Jupyter notebook.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ðŸ¤– Customer Support Bot - Demo Mode\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Running demo conversation...\\n\")\n",
    "    \n",
    "    thread_id = \"demo-session\"\n",
    "    \n",
    "    demo_messages = [\n",
    "        \"Hi, I need help with my order\",\n",
    "        \"My order number is 123456\",\n",
    "        \"When will it arrive?\",\n",
    "        \"What's your return policy?\",\n",
    "        \"I want to return order #789012 because it's defective\",\n",
    "        \"Do you have laptops in stock?\"\n",
    "    ]\n",
    "    \n",
    "    for message in demo_messages:\n",
    "        print(f\"ðŸ’¬ You: {message}\")\n",
    "        print(\"-\" * 60)\n",
    "        chat_with_memory(message, thread_id)\n",
    "        print()\n",
    "\n",
    "# For Jupyter notebooks, use demo_chat() instead of interactive_chat()\n",
    "# interactive_chat()  # This doesn't work well in Jupyter\n",
    "demo_chat()  # This works better in Jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from ipywidgets) (9.6.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/aperritano/dev/interviews/focused-io-agent-engineer/langgraph-customer-support-agent/.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7b/n8kzcb1d3xnb4t_1q8mh5nj80000gn/T/ipykernel_84170/842222697.py:61: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  text_input.on_submit(on_enter_pressed)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acd12677d4d47f3bbd6ddaec6ccdfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='You:', layout=Layout(width='70%'), placeholder='Type your message hâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ae118bfb1c4d07a8fe2a771cff8a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Customer Support Bot - Interactive Widget Mode\n",
      "Type your message and press Enter or click Send\n",
      "ðŸ“ Note: For true interactive chat in Jupyter, install ipywidgets:\n",
      "pip install ipywidgets\n",
      "Then uncomment the code above to use widget-based chat\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Text' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mcreate_interactive_chat.<locals>.on_enter_pressed\u001b[39m\u001b[34m(event)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_enter_pressed\u001b[39m(event):\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mkey\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m == \u001b[33m'\u001b[39m\u001b[33mEnter\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     56\u001b[39m         on_send_clicked(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: 'Text' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Alternative: Interactive chat using ipywidgets (works better in Jupyter)\n",
    "# Uncomment the lines below if you have ipywidgets installed: \n",
    "%pip install ipywidgets\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def create_interactive_chat():\n",
    "    # Create input widget\n",
    "    text_input = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Type your message here...',\n",
    "        description='You:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='70%')\n",
    "    )\n",
    "    \n",
    "    # Create output widget\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Create button\n",
    "    send_button = widgets.Button(\n",
    "        description='Send',\n",
    "        button_style='primary',\n",
    "        layout=widgets.Layout(width='20%')\n",
    "    )\n",
    "    \n",
    "    # Create quit button\n",
    "    quit_button = widgets.Button(\n",
    "        description='Quit',\n",
    "        button_style='danger',\n",
    "        layout=widgets.Layout(width='20%')\n",
    "    )\n",
    "    \n",
    "    thread_id = \"widget-session\"\n",
    "    \n",
    "    def on_send_clicked(b):\n",
    "        with output:\n",
    "            message = text_input.value.strip()\n",
    "            if message:\n",
    "                print(f\"ðŸ’¬ You: {message}\")\n",
    "                print(\"-\" * 60)\n",
    "                chat_with_memory(message, thread_id)\n",
    "                print()\n",
    "                text_input.value = ''  # Clear input\n",
    "    \n",
    "    def on_quit_clicked(b):\n",
    "        with output:\n",
    "            print(\"\\nðŸ‘‹ Goodbye!\\n\")\n",
    "        text_input.disabled = True\n",
    "        send_button.disabled = True\n",
    "        quit_button.disabled = True\n",
    "    \n",
    "    def on_enter_pressed(event):\n",
    "        if event['key'] == 'Enter':\n",
    "            on_send_clicked(None)\n",
    "    \n",
    "    # Bind events\n",
    "    send_button.on_click(on_send_clicked)\n",
    "    quit_button.on_click(on_quit_clicked)\n",
    "    text_input.on_submit(on_enter_pressed)\n",
    "    \n",
    "    # Display widgets\n",
    "    display(widgets.HBox([text_input, send_button, quit_button]))\n",
    "    display(output)\n",
    "    \n",
    "    print(\"ðŸ¤– Customer Support Bot - Interactive Widget Mode\")\n",
    "    print(\"Type your message and press Enter or click Send\")\n",
    "\n",
    "# Uncomment to use widget-based chat (requires ipywidgets)\n",
    "create_interactive_chat()\n",
    "\n",
    "print(\"ðŸ“ Note: For true interactive chat in Jupyter, install ipywidgets:\")\n",
    "print(\"pip install ipywidgets\")\n",
    "print(\"Then uncomment the code above to use widget-based chat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Customer Support Bot - Quick Chat Mode\n",
      "============================================================\n",
      "Type your messages below. Type 'quit' to exit.\n",
      "\n",
      "Try these test messages:\n",
      "1. Hi, I need help with my order\n",
      "2. My order number is 123456\n",
      "3. When will it arrive?\n",
      "4. What's your return policy?\n",
      "5. Do you have laptops in stock?\n",
      "6. quit\n",
      "\n",
      "Or test individual messages:\n",
      "chat_with_memory('your message here', 'test-session')\n",
      "\n",
      "============================================================\n",
      "Testing with: 'Hi, I need help with my order'\n",
      "============================================================\n",
      "ðŸ’¬ You: Hi, I need help with my order\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Using tool: search_knowledge_base\n",
      "\n",
      "ðŸ¤– Bot: I'd be happy to help you with your order! Can you please provide me with your order number so I can look into it further?\n",
      "\n",
      "\n",
      "âœ… Chat system is working!\n",
      "\n",
      "To chat interactively, use:\n",
      "chat_with_memory('your message', 'session-name')\n"
     ]
    }
   ],
   "source": [
    "# Quick Fix: Simple Interactive Chat\n",
    "# This will work if you've run all previous cells\n",
    "\n",
    "def quick_chat():\n",
    "    \"\"\"Simple interactive chat that works in Jupyter.\"\"\"\n",
    "    print(\"ðŸ¤– Customer Support Bot - Quick Chat Mode\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Type your messages below. Type 'quit' to exit.\\n\")\n",
    "    \n",
    "    thread_id = \"quick-session\"\n",
    "    \n",
    "    # Test messages to try\n",
    "    test_messages = [\n",
    "        \"Hi, I need help with my order\",\n",
    "        \"My order number is 123456\", \n",
    "        \"When will it arrive?\",\n",
    "        \"What's your return policy?\",\n",
    "        \"Do you have laptops in stock?\",\n",
    "        \"quit\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Try these test messages:\")\n",
    "    for i, msg in enumerate(test_messages, 1):\n",
    "        print(f\"{i}. {msg}\")\n",
    "    \n",
    "    print(\"\\nOr test individual messages:\")\n",
    "    print(\"chat_with_memory('your message here', 'test-session')\")\n",
    "    \n",
    "    # Test one message to make sure everything works\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Testing with: 'Hi, I need help with my order'\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        chat_with_memory(\"Hi, I need help with my order\", thread_id)\n",
    "        print(\"\\nâœ… Chat system is working!\")\n",
    "        print(\"\\nTo chat interactively, use:\")\n",
    "        print(\"chat_with_memory('your message', 'session-name')\")\n",
    "    except NameError as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        print(\"Please run all previous cells first (cells 1-27)\")\n",
    "\n",
    "# Run the quick chat\n",
    "quick_chat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 14: Analyze Tool Usage\n",
    "\n",
    "See which tools were called most often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing multiple queries...\n",
      "\n",
      "Query: What's your return policy?\n",
      "  â†’ Used: search_knowledge_base\n",
      "\n",
      "Query: Check order #123456\n",
      "  â†’ Used: get_order_status\n",
      "\n",
      "Query: Do you have laptops?\n",
      "  â†’ Used: check_product_availability\n",
      "\n",
      "Query: I want to return order #789012\n",
      "  â†’ Used: initiate_return\n",
      "\n",
      "Query: What's your shipping policy?\n",
      "  â†’ Used: search_knowledge_base\n",
      "\n",
      "Query: Check order #789012\n",
      "  â†’ Used: get_order_status\n",
      "\n",
      "\n",
      "ðŸ“Š Tool Usage Statistics:\n",
      "----------------------------------------\n",
      "  search_knowledge_base: 2 times\n",
      "  get_order_status: 2 times\n",
      "  check_product_availability: 1 times\n",
      "  initiate_return: 1 times\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Test multiple queries\n",
    "test_queries = [\n",
    "    \"What's your return policy?\",\n",
    "    \"Check order #123456\",\n",
    "    \"Do you have laptops?\",\n",
    "    \"I want to return order #789012\",\n",
    "    \"What's your shipping policy?\",\n",
    "    \"Check order #789012\",\n",
    "]\n",
    "\n",
    "tool_usage = Counter()\n",
    "\n",
    "print(\"Testing multiple queries...\\n\")\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"Query: {query}\")\n",
    "    \n",
    "    for event in graph.stream(\n",
    "        {\"messages\": [HumanMessage(content=query)]},\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        last_msg = event[\"messages\"][-1]\n",
    "        \n",
    "        if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
    "            for tc in last_msg.tool_calls:\n",
    "                tool_usage[tc[\"name\"]] += 1\n",
    "                print(f\"  â†’ Used: {tc['name']}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nðŸ“Š Tool Usage Statistics:\")\n",
    "print(\"-\" * 40)\n",
    "for tool, count in tool_usage.most_common():\n",
    "    print(f\"  {tool}: {count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Step 15: Performance Testing\n",
    "\n",
    "Measure response times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸  Performance Benchmarks:\n",
      "============================================================\n",
      "\n",
      "Simple query: 2.09s\n",
      "  Query: What's your return policy?\n",
      "  Response length: 190 chars\n",
      "\n",
      "Tool call query: 2.15s\n",
      "  Query: Check order #123456\n",
      "  Response length: 214 chars\n",
      "\n",
      "Multi-tool query: 3.56s\n",
      "  Query: Check order #123456 and tell me your warranty policy\n",
      "  Response length: 372 chars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_query(query: str):\n",
    "    \"\"\"Benchmark a single query.\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    result = None\n",
    "    for event in graph.stream(\n",
    "        {\"messages\": [HumanMessage(content=query)]},\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        last_msg = event[\"messages\"][-1]\n",
    "        if hasattr(last_msg, \"content\") and last_msg.type == \"ai\":\n",
    "            result = last_msg.content\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    return elapsed, result\n",
    "\n",
    "# Benchmark different query types\n",
    "benchmarks = [\n",
    "    (\"Simple\", \"What's your return policy?\"),\n",
    "    (\"Tool call\", \"Check order #123456\"),\n",
    "    (\"Multi-tool\", \"Check order #123456 and tell me your warranty policy\"),\n",
    "]\n",
    "\n",
    "print(\"â±ï¸  Performance Benchmarks:\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "for name, query in benchmarks:\n",
    "    elapsed, response = benchmark_query(query)\n",
    "    print(f\"{name} query: {elapsed:.2f}s\")\n",
    "    print(f\"  Query: {query}\")\n",
    "    print(f\"  Response length: {len(response) if response else 0} chars\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Step 16: Customization Examples\n",
    "\n",
    "How to modify the bot for your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Example 1: Add a new tool\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;129;43m@tool\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mcheck_warranty\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mproduct_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"Check warranty information for a product.\"\"\"\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mThe \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mproduct_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m comes with a standard 30-day warranty. Extended warranties available.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n",
      "\u001b[31mTypeError\u001b[39m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "# Example 1: Add a new tool\n",
    "@tool\n",
    "def check_warranty(product_name: str) -> str:\n",
    "    \"\"\"Check warranty information for a product.\"\"\"\n",
    "    return f\"The {product_name} comes with a standard 30-day warranty. Extended warranties available.\"\n",
    "\n",
    "# Example 2: Change the system prompt\n",
    "CUSTOM_PROMPT = \"\"\"You are a super friendly support agent who loves emojis! ðŸ˜Š\n",
    "Always be enthusiastic and use emojis in your responses.\n",
    "Use the available tools to help customers.\"\"\"\n",
    "\n",
    "# Example 3: Use a different model\n",
    "# llm = ChatOllama(model=\"mistral:7b\", temperature=0.3)\n",
    "\n",
    "print(\"âœ… Customization examples shown above\")\n",
    "print(\"\\nTo apply:\")\n",
    "print(\"1. Add new tools to the 'tools' list\")\n",
    "print(\"2. Update SYSTEM_PROMPT variable\")\n",
    "print(\"3. Rebuild the graph with: graph = workflow.compile()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Summary & Next Steps\n",
    "\n",
    "### What We Built\n",
    "âœ… Complete customer support agent\n",
    "âœ… 5 working tools (KB search, order tracking, returns, inventory, escalation)\n",
    "âœ… ReAct pattern (reasoning + acting)\n",
    "âœ… Conversation memory\n",
    "âœ… Local LLM with Ollama (no API costs!)\n",
    "\n",
    "### Key Concepts\n",
    "- **Tools**: Actions the agent can take\n",
    "- **State**: Data that flows through the graph\n",
    "- **Nodes**: Processing steps (agent reasoning, tool execution)\n",
    "- **Edges**: Flow control (conditional routing)\n",
    "- **Memory**: Conversation history persistence\n",
    "\n",
    "### Next Steps\n",
    "1. **Add more tools** for your specific use case\n",
    "2. **Connect real systems** (databases, APIs, CRM)\n",
    "3. **Add RAG** with vector search for better knowledge retrieval\n",
    "4. **Deploy** as a web service with LangGraph Dev\n",
    "5. **Monitor** tool usage and conversation quality\n",
    "\n",
    "### Resources\n",
    "- [LangGraph Docs](https://langchain-ai.github.io/langgraph/)\n",
    "- [Ollama Models](https://ollama.ai/library)\n",
    "- [LangChain Tools](https://python.langchain.com/docs/modules/agents/tools/)\n",
    "\n",
    "### Full Project\n",
    "For a production-ready version with:\n",
    "- Full documentation\n",
    "- CLI and API interfaces\n",
    "- Docker support\n",
    "- Testing suite\n",
    "\n",
    "See the `customer-support-bot.zip` file!\n",
    "\n",
    "---\n",
    "\n",
    "**Happy building! ðŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
